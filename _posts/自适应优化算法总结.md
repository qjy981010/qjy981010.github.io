---
title: 自适应优化算法总结
date: 2017-12-23 13:31:55
tags: ['自适应','优化','算法','机器学习']
author: Jiyang Qi
---

在机器学习中，优化算法即优化模型并使损失尽量减小的算法，我们常用的比如梯度下降就属于优化算法。而从梯度下降法延伸出来的一些优化算法，在应用中遇到的一个问题就是学习速率的选择。
- 学习速率选的小，收敛就慢
- 学习速率选的大，训练效果不好

而且一般情况下，我们希望学习速率在开始时比较大，之后随着训练的进行，学习速率能适当调整。于是自适应优化算法就出现了。

本文将介绍一下四种自适应优化算法:
- Adagrad
- AdaDelta
- RMSprop
- Adam

# Adagrad
